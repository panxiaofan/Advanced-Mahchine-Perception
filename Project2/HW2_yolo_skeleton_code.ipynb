{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_yolo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_81AzUzv07i",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "This first code block attaches your google drive and makes a folder structure. You only need to run this when a new VM is assigned to you. To get your code as a single python file go through the following menus File->'Download .py'.\n",
        "\n",
        "This also downloads 2 npz files for your use: labels.npz and images.npz. For those not using colab you can download manually here:\n",
        "\n",
        "https://drive.google.com/open?id=1jIKQLhTHZUE6m2mE5lRKMSqN7ZGK2Gyu\n",
        "\n",
        "https://drive.google.com/open?id=1Gth_AVG5t-4ZhH_whOaXwe0PBXNhIIK0\n",
        "\n",
        "https://drive.google.com/file/d/1tkpFDxbpP61OEic7EP4LOhUKclYJLlwr/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdTi3p-ZvNHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O24ne8z-vaJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount google drive\n",
        "DRIVE_MOUNT='/content/drive'\n",
        "drive.mount(DRIVE_MOUNT)\n",
        "\n",
        "\n",
        "# create folder to write data to\n",
        "CIS680_FOLDER=os.path.join(DRIVE_MOUNT, 'My Drive', 'CIS680_2019')\n",
        "HOMEWORK_FOLDER=os.path.join(CIS680_FOLDER, 'HW2')\n",
        "os.makedirs(HOMEWORK_FOLDER, exist_ok=True)\n",
        "\n",
        "# bootstrap environment into place\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "import io\n",
        "import os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "def download_file(fn, file_id):\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    downloaded = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(downloaded, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "        # _ is a placeholder for a progress object that we ignore.\n",
        "        # (Our file is small, so we skip reporting progress.)\n",
        "        _, done = downloader.next_chunk()\n",
        "    \n",
        "    downloaded.seek(0)\n",
        "\n",
        "    folder = fn.split('/')\n",
        "    if len(folder) > 1:\n",
        "        os.makedirs(folder[0], exist_ok=True)\n",
        "\n",
        "    with open(fn, 'wb') as f:\n",
        "        f.write(downloaded.read())\n",
        "\n",
        "id_to_fn = {\n",
        "    '1Gth_AVG5t-4ZhH_whOaXwe0PBXNhIIK0': 'labels.npz',\n",
        "    '1jIKQLhTHZUE6m2mE5lRKMSqN7ZGK2Gyu': 'images.npz',\n",
        "    '1tkpFDxbpP61OEic7EP4LOhUKclYJLlwr': 'test_y_label.npz'       }\n",
        "\n",
        "# download all files into the vm\n",
        "for fid, fn in id_to_fn.items():\n",
        "    download_file(fn, fid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ7XGblg2w_P",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Here you will implement a pytorch data processor that loads tha images and computes the ground truth labels as described in the PDF.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24fZjFVT3YjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def loadData(image_path, labels_path):\n",
        "  ## use 0.8*no_images as the training data and the remaining as test data.\n",
        "\n",
        "\n",
        "  return train_images, train_raw_lables, test_images, test_raw_labels.\n",
        "\n",
        "def create_y_label(image, raw_label):\n",
        "  ## this function should compute the 8X8X8 label from the raw labels for the corresponding image.\n",
        "\n",
        "\n",
        "  return y_label\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX2Mh2St75U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWf5lWIK66QU",
        "colab_type": "text"
      },
      "source": [
        "TEST your processed y_labels.\n",
        "\n",
        "The following test checks your create_y_labels function using the test_y_label.npz file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVr7tgIfsTvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09cf2d4d-0be2-4382-d71d-008217ca283d"
      },
      "source": [
        "\n",
        "data = np.load(\"test_y_label.npz\",allow_pickle=True)\n",
        "## the test data contains 5 - (image, raw_label, processed_label) that is 5 test cases \n",
        "\n",
        "img = data['image']   ## shape (5,3,128,18)\n",
        "raw_label = data['raw_label']\n",
        "true_y_label = data['y_label']  ## shape (5,8,8,8)\n",
        "\n",
        "## fill in your code to compute the your processed y_label\n",
        "y_label = np.zeros((5,8,8,8))\n",
        "\n",
        "for i, label in enumerate(raw_labels):\n",
        "  y_label[i] = create_y_label(img[i], label)\n",
        "\n",
        "\n",
        "\n",
        "# test you processed labels\n",
        "for i in range(len(img)):\n",
        "  comparison = y_label[i] == true_y_label[i]\n",
        "  equal_arrays = comparison.all()\n",
        "  print('Completed TEST CASE {}: {}'.format(i+1,equal_arrays))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 8, 8, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fErrCGJeAg_m",
        "colab_type": "text"
      },
      "source": [
        "Test your DATASET\n",
        "\n",
        "Test your data processing by plotting the images and the processed labels. Compare against the raw labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUuvSfAM7GSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3lPzBlowKyc",
        "colab_type": "text"
      },
      "source": [
        "Set up the data set for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byHERvO_zXp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "## use the processed labels and use the correct image dimensions for the pytorch loader.\n",
        "## images = images.transpose(0,3,1,2)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T6uUevnBLGr",
        "colab_type": "text"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbZ3ReXQBQvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class YOLO(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "  def forward(self, X):\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac2gFUgpBf6S",
        "colab_type": "text"
      },
      "source": [
        "# Training you network\n",
        "\n",
        "Start by defining the \n",
        "1. IOU\n",
        "2. appropropriate loss function.\n",
        "3. NMS - non-max suppression function\n",
        "4. Average precision function\n",
        "\n",
        "Please define additional functions as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSHSW3zfBqZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def IOU(prediction, grnd_truth):\n",
        "   ## please fill in additional arguements\n",
        "\n",
        "  return iou\n",
        "\n",
        "def YoloLoss(output, target, lambda_coord, lambda_noobj):\n",
        "  ## please fill in additional arguements\n",
        "  return loss\n",
        "\n",
        "\n",
        "def NSM(nw_output):\n",
        "   ## please fill in additional arguements\n",
        "  return nms_output\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "def average_precision():\n",
        "  ## please fill in the appropriate arguements \n",
        "  ## compute the average precision as mentioned in the PDF.\n",
        "  ## it might be helpful to use - from sklearn.metrics import auc to compute area under the curve.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMwZGu_rDQwC",
        "colab_type": "text"
      },
      "source": [
        "**Train your network **\n",
        "\n",
        "We suggest that you save checkpoints sand reload from the most recent. This is due time constraints within Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGozjqioDhb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = # set this to where the checkpoint is saved \n",
        "resume = False # set this True if you want to resume training from a checkpoint\n",
        "\n",
        "yolo_net=YOLO()\n",
        "device = ## initilize device to cpu or cuda\n",
        "yolo_net=yolo_net.to(device)\n",
        "\n",
        "learning_rate = 10e-3 \n",
        "\n",
        "## intialize optimizer\n",
        "optimizer=torch.optim.Adam(yolo_net.parameters(),lr=learning_rate,weight_decay=0.0006)\n",
        "\n",
        "if resume == True:\n",
        "  checkpoint = torch.load(path)\n",
        "  yolo_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  \n",
        "num_epochs = ## intialize this, atleast 20 epoch required for training\n",
        " \n",
        "for epochs in range(num_epochs):\n",
        "    ## fill in your training code\n",
        "\n",
        "\n",
        "\n",
        "    ## this is sample code for saving checkpoints, please set the appropriate path, \n",
        "    ## additional values and feel free to move the snippet if required.\n",
        "\n",
        "  path = os.path.join('','yolo_epoch'+str(epoch))\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': yolo_net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, path)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Wf6SY5k4gc",
        "colab_type": "text"
      },
      "source": [
        "# Test your network.\n",
        "Use the test images you created in the data preprocessing step. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ4rHTBKlWgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = ## intialise the path where the model has been saved \n",
        "checkpoint = torch.load(path)\n",
        "yolo_net.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}